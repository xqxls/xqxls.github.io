### 1.场景描述

抽奖系统中，对于活动参与流程下的库存扣减操作，原来是使用数据库行级锁处理的库存扣减，但因为会存在并发问题所以需要优化为 Redis 分布式锁进行处理。

### 2.方案设计

分布式锁流程：

- 获取抽奖活动库存 Key
- 扣减库存，目前占用库存数
- 超出库存判断，进行恢复原始库存
- 以活动库存占用编号，生成对应加锁Key，细化锁的颗粒度
- 使用 Redis.setNx 加一个分布式锁
- 删除分布式锁 Key

活动领取完成后，其实这个时候只是把缓存的库存扣掉了，但数据库中的库存并没有扣减，所以我们需要发送一个 MQ 消息，来对数据库中的库存进行处理。因为 MQ 可以消峰因此在降低 MQ 分片的情况下，消费效率有所下降，并不会对数据库造成压力，保证最终数据一致性即可。但也有例外，所以我们提到可以使用定时任务来更新数据库库存。

### 3.数据库表结构

```sql
CREATE TABLE `activity` (
  `id` bigint NOT NULL AUTO_INCREMENT COMMENT '自增ID',
  `activity_id` bigint NOT NULL COMMENT '活动ID',
  `activity_name` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT '活动名称',
  `activity_desc` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT '活动描述',
  `begin_date_time` datetime DEFAULT NULL COMMENT '开始时间',
  `end_date_time` datetime DEFAULT NULL COMMENT '结束时间',
  `stock_count` int DEFAULT NULL COMMENT '库存',
  `stock_surplus_count` int DEFAULT NULL COMMENT '库存剩余',
  `take_count` int DEFAULT NULL COMMENT '每人可参与次数',
  `strategy_id` bigint DEFAULT NULL COMMENT '抽奖策略ID',
  `state` tinyint DEFAULT NULL COMMENT '活动状态：1编辑、2提审、3撤审、4通过、5运行(审核通过后worker扫描状态)、6拒绝、7关闭、8开启',
  `creator` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT '创建人',
  `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `unique_activity_id` (`activity_id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT='活动配置';
```

### 4.核心代码

数据库行级锁：

```java
public class ActivityRepository{
		@Override
    public int subtractionActivityStock(Long activityId) {
        return activityDao.subtractionActivityStock(activityId);
    }
}
```

扣减库存Sql:

```sql
UPDATE activity SET stock_surplus_count = stock_surplus_count - 1
        WHERE activity_id = #{activityId} AND stock_surplus_count > 0
```

Redis分布式锁：

```java
public class ActivityRepository{
  	@Override
    public StockResult subtractionActivityStockByRedis(String uId, Long activityId, Integer stockCount) {
        //  1. 获取抽奖活动库存 Key
        String stockKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT(activityId);

        // 2. 扣减库存，目前占用库存数
        Integer stockUsedCount = (int) redisUtil.incr(stockKey, 1);

        // 3. 超出库存判断，进行恢复原始库存
        if (stockUsedCount > stockCount) {
            redisUtil.decr(stockKey, 1);
            return new StockResult(Constants.ResponseCode.OUT_OF_STOCK.getCode(), Constants.ResponseCode.OUT_OF_STOCK.getInfo());
        }

        // 4. 以活动库存占用编号，生成对应加锁Key，细化锁的颗粒度
        String stockTokenKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN(activityId, stockUsedCount);

        // 5. 使用 Redis.setNx 加一个分布式锁
        boolean lockToken = redisUtil.setNx(stockTokenKey, 350L);
        if (!lockToken) {
            logger.info("抽奖活动{}用户秒杀{}扣减库存，分布式锁失败：{}", activityId, uId, stockTokenKey);
            return new StockResult(Constants.ResponseCode.ERR_TOKEN.getCode(), Constants.ResponseCode.ERR_TOKEN.getInfo());
        }

        return new StockResult(Constants.ResponseCode.SUCCESS.getCode(), Constants.ResponseCode.SUCCESS.getInfo(), stockTokenKey, stockCount - stockUsedCount);
    }
  
  	@Override
    public void recoverActivityCacheStockByRedis(Long activityId, String tokenKey, String code) {
        // 删除分布式锁 Key
        redisUtil.del(tokenKey);
    }
  	
}
```

RedisKey类：

```java
public static final class RedisKey {

    // 抽奖活动库存 Key
    private static final String LOTTERY_ACTIVITY_STOCK_COUNT = "lottery_activity_stock_count_";

    public static String KEY_LOTTERY_ACTIVITY_STOCK_COUNT(Long activityId) {
      return LOTTERY_ACTIVITY_STOCK_COUNT + activityId;
    }

    // 抽奖活动库存锁 Key
    private static final String LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN = "lottery_activity_stock_count_token_";

    public static String KEY_LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN(Long activityId, Integer stockUsedCount) {
      return LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN + activityId + "_" + stockUsedCount;
    }
}
```

即使是使用 Redis 分布式锁，我们也不希望把锁的颗粒度放的太粗，否则还是会出现活动有库存但不能秒杀，提示“活动过于火爆”，所以我们就需要按照活动编号把库存锁的颗粒度缩小，实际操作也并不复杂，只是把`活动ID+库存扣减后的值`一起作为分布式锁的Key，这样就缩小了锁的颗粒度。

Redis分布式锁工具类：

```java
@Component
public class RedisUtil {

    @Resource
    private RedisTemplate<String, Object> redisTemplate;

    public RedisUtil(RedisTemplate<String, Object> redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    /**
     * 分布式锁
     * @param key               锁住的key
     * @param lockExpireMils    锁住的时长。如果超时未解锁，视为加锁线程死亡，其他线程可夺取锁
     * @return
     */
    public boolean setNx(String key, Long lockExpireMils) {
        return (boolean) redisTemplate.execute((RedisCallback) connection -> {
            //获取锁
            return connection.setNX(key.getBytes(), String.valueOf(System.currentTimeMillis() + lockExpireMils + 1).getBytes());
        });
    }

    /**
     * 递增
     *
     * @param key   键
     * @param delta 要增加几(大于0)
     * @return
     */
    public long incr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递增因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, delta);
    }

    /**
     * 递减
     *
     * @param key   键
     * @param delta 要减少几(小于0)
     * @return
     */
    public long decr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递减因子必须大于0");
        }
        return redisTemplate.opsForValue().increment(key, -delta);
    }

  	/**
     * 删除缓存
     *
     * @param key 可以传一个值 或多个
     */
    @SuppressWarnings("unchecked")
    public void del(String... key) {
        if (key != null && key.length > 0) {
            if (key.length == 1) {
                redisTemplate.delete(key[0]);
            } else {
                redisTemplate.delete((Collection<String>) CollectionUtils.arrayToList(key));
            }
        }
    }
}
```

秒杀完毕后，接下来的流程是用户记录落库，但可能这个时候会发生失败的情况，因为需要在失败时恢复缓存的库存。不过这个情况不是事务性的，因此可能会恢复失败，也就是保证不超卖，但不能保证一定完全消耗库存。

如果最后的操作是成功的，那么正常删除掉这个加锁的 Key 就可以了，因为下一个用户获取的到的库存滑块又是新的了，旧 Key 已经没有用了。

### 5.发送MQ消息，处理数据一致性

由于我们使用 Redis 代替数据库库存，那么在缓存的库存处理后，还需要把数据库中的库存处理为和缓存一致，这样在后续运营这部分数据时才能保证一定的运营可靠性。

```java
public class ActivityProcessImpl {
  	@Override
    public DrawProcessResult doDrawProcess(DrawProcessReq req) {
        // 1. 领取活动
        PartakeResult partakeResult = activityPartake.doPartake(new PartakeReq(req.getuId(), req.getActivityId()));
        if (!Constants.ResponseCode.SUCCESS.getCode().equals(partakeResult.getCode()) && !Constants.ResponseCode.NOT_CONSUMED_TAKE.getCode().equals(partakeResult.getCode())) {
            return new DrawProcessResult(partakeResult.getCode(), partakeResult.getInfo());
        }
        // 2. 首次成功领取活动，发送MQ消息
        if(Constants.ResponseCode.SUCCESS.getCode().equals(partakeResult.getCode())){
            ActivityPartakeRecordVO activityPartakeRecordVO = new ActivityPartakeRecordVO();
            activityPartakeRecordVO.setuId(req.getuId());
            activityPartakeRecordVO.setActivityId(req.getActivityId());
            activityPartakeRecordVO.setStockCount(partakeResult.getStockCount());
            activityPartakeRecordVO.setStockSurplusCount(partakeResult.getStockSurplusCount());
            // 发送 MQ 消息
            kafkaProducer.sendLotteryActivityPartakeRecord(activityPartakeRecordVO);
        }
    }
}
```

### 6.活动领取记录 MQ 消费

```java
@Component
public class LotteryActivityPartakeRecordListener {

    private Logger logger = LoggerFactory.getLogger(LotteryActivityPartakeRecordListener.class);

    @Resource
    private IActivityPartake activityPartake;

    @KafkaListener(topics = "lottery_activity_partake", groupId = "lottery")
    public void onMessage(ConsumerRecord<?, ?> record, Acknowledgment ack, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {
        Optional<?> message = Optional.ofNullable(record.value());

        // 1. 判断消息是否存在
        if(!message.isPresent()){
            return;
        }

        // 2. 转化对象
        ActivityPartakeRecordVO activityPartakeRecordVO = JSON.parseObject((String)message.get(),ActivityPartakeRecordVO.class);
        logger.info("消费MQ消息，异步扣减活动库存 message：{}", message.get());

        // 3. 更新数据库库存【实际场景业务体量较大，可能也会由于MQ消费引起并发，对数据库产生压力，所以如果并发量较大，可以把库存记录缓存中，并使用定时任务进行处理缓存和数据库库存同步，减少对数据库的操作次数】
        activityPartake.updateActivityStock(activityPartakeRecordVO);
    }
}
```

更新数据库库存sql：

```sql
UPDATE activity SET stock_surplus_count = #{stockSurplusCount}
        WHERE activity_id = #{activityId} AND stock_surplus_count > #{stockSurplusCount}
```

