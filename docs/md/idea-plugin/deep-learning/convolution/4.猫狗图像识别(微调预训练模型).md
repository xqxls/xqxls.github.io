
## 任务描述
> 给定一个图像，识别是猫还是狗 

![1683728953448](3.猫狗图像识别(预训练模型特征提取).assets/1683728953448.png)

## 数据集介绍

> 猫狗分类数据集由 Kaggle 提供，在 2013 年底作为一项计算机视觉竞赛的一部分，当时卷积神经网络还不是主流算法。可以从 Kaggle 网站下载原始数据集 Dogs vs. Cats。
>
> 这个数据集包含 25 000 张猫和狗的图像（每个类别各有 12 500 张），压缩后的大小为 543 MB。

## 步骤一（下载数据集）

```
!curl https://public.dm.files.1drv.com/y4meMrMBWeYXOWWjpFj7fxpAbOeVTS1XolBX-uO90dlZQzsdvWcAvkk5Gwj3-ctSZXa8Ho0y_QTCjuRHSlwUzze-0Tx_k6Sm2cCW8g9C3alGcO0X4vl1jdR3LHQeP4pcLe1p4X5xGhjeFi7gtszZOhxjFUkx4HjViPJCG85ntgKzsAmI5vjq3UzSMOrknmoZQLTU1C-Dx6ExxexemZofNrIfqHWJkz4GXgmNiH3CyD6R2U?AVOverride=1 --output /content/train.zip
```

首先从kaggle下载Dogs vs. Cats数据集，下载下来是一个train.zip格式的文件。由于谷歌的Colab上传文件太慢，可以先上传到oneDrive平台，再通过curl从平台下载下来。

可以看到train.zip文件有500多M，说明下载成功。

## 步骤二（解压并提取数据）

```
!unzip -qq train.zip
```

解压之后多了一个train目录

```
import os, shutil, pathlib
original_dir = pathlib.Path("train")   
new_base_dir = pathlib.Path("cats_vs_dogs_small")   

def make_subset(subset_name, start_index, end_index):   
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg"
                  for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train", start_index=0, end_index=1000)   
make_subset("validation", start_index=1000, end_index=1500)   
make_subset("test", start_index=1500, end_index=2500) 
```

下载数据并解压后，我们将创建一个新数据集，其中包含 3 个子集：训练集，每个类别各 1000 个样本；验证集，每个类别各 500 个样本；测试集，每个类别各 1000 个样本。我们通过调用几次 shutil 来创建这个子数据集。

发现多了一个cats_vs_dogs_small目录

train是用每个类别的前 1000 张图像创建的训练子集，test是 用每个类别接下来的 500 张图像创建验证子集 ，validation是用每个类别接下来的 1000 张图像创建测试子集 。

现在我们有 2000 张训练图像、1000 张验证图像和 2000 张测试图像。在这 3 个集合中，两个类别的样本数相同，所以这是一个均衡的二分类问题，分类精度可作为衡量成功的指标。

## 步骤三（数据预处理）

```
from tensorflow.keras.utils import image_dataset_from_directory
train_dataset = image_dataset_from_directory(
    new_base_dir / "train",
    image_size=(180, 180),
    batch_size=32)
validation_dataset = image_dataset_from_directory(
    new_base_dir / "validation",
    image_size=(180, 180),
    batch_size=32)
test_dataset = image_dataset_from_directory(
    new_base_dir / "test",
    image_size=(180, 180),
    batch_size=32)
```

将数据输入模型之前，应该将数据格式化为经过预处理的浮点数张量。当前数据以 JPEG 文件的形式存储在硬盘上，所以数据预处理步骤大致如下。

- 读取 JPEG 文件。
- 将 JPEG 文件解码为 RGB 像素网格。
- 将这些像素网格转换为浮点数张量。
- 将这些张量调节为相同大小（本例为 180×180）。
- 将数据打包成批量（一个批量包含 32 张图像）。

Keras 拥有自动完成这些步骤的工具。具体地说，Keras 包含实用函数 image_dataset_from_directory()，它可以快速建立数据管道，自动将磁盘上的图像文件转换为预处理好的张量批量。

调用 image_dataset_from_directory(directory)，首先会列出 directory 的子目录，并假定每个子目录都包含某一个类别的图像。然后，它会为每个子目录下的图像文件建立索引。最后，它会创建并返回一个 tf.data.Dataset 对象，用于读取这些文件、打乱其顺序、将其调节为相同大小并打包成批量。

## 步骤四（将 VGG16 卷积基实例化 ）

```
from tensorflow import keras
conv_base = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False,
    input_shape=(180, 180, 3))
```

这里向构造函数传入了 3 个参数：

- weights 指定模型初始化的权重检查点。
- include_top 指定是否包含密集连接分类器。默认情况下，这个密集连接分类器对应 ImageNet 的 1000 个类别。由于我们打算使用自己的密集连接分类器（只有 cat 和 dog 这两个类别），因此不需要包含它。
- input_shape 是输入模型的图像张量的形状。这个参数完全是可选的。如果不传入这个参数，那么模型能够处理任意形状的输入。这里我们传入这个参数，以便直观地观察特征图的尺寸如何随着每个新的卷积层和汇聚层而减小。

接下来有以下两种方法可供选择：

- 在我们的数据集上运行卷积基，将输出保存为 NumPy 数组，并保存在硬盘上，然后将这个数组输入到一个独立的密集连接分类器中。这种方法速度快，计算代价低，因为对于每张输入图像只需运行一次卷积基，而卷积基是当前流程中计算代价最高的。但出于同样的原因，这种方法无法使用数据增强。
- 在已有模型（conv_base）上添加 Dense 层，并在输入数据上端到端地运行整个模型。这样就可以使用数据增强，因为每张输入图像进入模型时都会经过卷积基。但出于同样的原因，这种方法的计算代价比第一种要高很多。

## 步骤五（使用数据增强的特征提取）

将 VGG16 卷积基实例化并冻结 

```
conv_base = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False)
conv_base.trainable = False
```

现在我们可以创建一个新模型，将以下三部分连接起来：

- 一个数据增强代码块
- 冻结的卷积基
- 一个密集连接分类器

```
data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)   
x = keras.applications.vgg16.preprocess_input(x)   
x = conv_base(x)
x = layers.Flatten()(x)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
    optimizer="rmsprop",
    metrics=["accuracy"])

```

## 步骤六（训练模型）

```
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="feature_extraction_with_data_augmentation.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=50,
    validation_data=validation_dataset,
    callbacks=callbacks)
```

![1684938294761](4.猫狗图像识别(微调预训练模型).assets/1684938294761.png)

## 步骤七（绘制精度曲线和损失曲线）

```
import matplotlib.pyplot as plt
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

![1684938395340](4.猫狗图像识别(微调预训练模型).assets/1684938395340.png)

​        

​          ![1684938535925](4.猫狗图像识别(微调预训练模型).assets/1684938535925.png)



## 步骤八（测试集上评估模型）

```
test_model = keras.models.load_model(
    "feature_extraction_with_data_augmentation.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")
```

![1684938565066](4.猫狗图像识别(微调预训练模型).assets/1684938565066.png)

模型的精度始终取决于评估模型的样本集。有些样本集可能比其他样本集更难以预测，在一个样本集上得到的好结果，并不一定能够在其他样本集上完全复现。

## 步骤九（微调 VGG16 网络 ）

冻结 VGG16 卷积基是为了能够在上面训练一个随机初始化的分类器。出于同样的原因，只有该分类器已经训练好，才能对卷积基的顶部几层进行微调。如果分类器没有训练好，那么训练过程中通过神经网络传播的误差信号将会非常大，微调的几层之前学到的表示将被破坏。因此，微调的步骤如下。

(1) 在已经训练好的基网络（base network）上添加自定义网络。

(2) 冻结基网络。

(3) 训练新添加的部分。

(4) 解冻基网络的一些层。

(5) 共同训练解冻的这些层和新添加的部分。

做特征提取时已经完成了前 3 个步骤。我们来完成第 4 步：先解冻 conv_base，然后冻结其中的部分层。 

```
conv_base.trainable = True
for layer in conv_base.layers[:-4]:
    layer.trainable = False
```

下面开始微调模型，我们将使用学习率很小的 RMSprop 优化器。之所以将学习率设置得很小，是因为对于微调的 3 层表示，我们希望其变化幅度不要太大。太大的权重更新可能会破坏这些表示。（下图中红线圈住的地方展示了微调的卷积层）

![1684939163938](4.猫狗图像识别(微调预训练模型).assets/1684939163938.png)

微调模型 ：

```
model.compile(loss="binary_crossentropy",
              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
    	filepath="fine_tuning.keras",
    	save_best_only=True,
    	monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=30,
    validation_data=validation_dataset,
    callbacks=callbacks)
```

![1684939276257](4.猫狗图像识别(微调预训练模型).assets/1684939276257.png)

## 步骤十（绘制精度曲线和损失曲线）

```
import matplotlib.pyplot as plt
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

![1684939358835](4.猫狗图像识别(微调预训练模型).assets/1684939358835.png)



​          ![1684939389823](4.猫狗图像识别(微调预训练模型).assets/1684939389823.png)

## 步骤十一（测试集上评估模型）

```
model = keras.models.load_model("fine_tuning.keras")
test_loss, test_acc = model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")
```

![1684939493694](4.猫狗图像识别(微调预训练模型).assets/1684939493694.png)

测试精度为 97.5%（同样，你得到的结果可能会有不到 1% 的差距）。 