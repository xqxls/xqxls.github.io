
## 任务描述
> 给定一个图像，识别是猫还是狗 

![1682802709369](2.猫狗图像识别.assets/1682802709369.png)

## 数据集介绍

> 猫狗分类数据集由 Kaggle 提供，在 2013 年底作为一项计算机视觉竞赛的一部分，当时卷积神经网络还不是主流算法。可以从 Kaggle 网站下载原始数据集 Dogs vs. Cats。
>
> 这个数据集包含 25 000 张猫和狗的图像（每个类别各有 12 500 张），压缩后的大小为 543 MB。



## 步骤一（下载数据集）

```
!curl https://public.dm.files.1drv.com/y4meMrMBWeYXOWWjpFj7fxpAbOeVTS1XolBX-uO90dlZQzsdvWcAvkk5Gwj3-ctSZXa8Ho0y_QTCjuRHSlwUzze-0Tx_k6Sm2cCW8g9C3alGcO0X4vl1jdR3LHQeP4pcLe1p4X5xGhjeFi7gtszZOhxjFUkx4HjViPJCG85ntgKzsAmI5vjq3UzSMOrknmoZQLTU1C-Dx6ExxexemZofNrIfqHWJkz4GXgmNiH3CyD6R2U?AVOverride=1 --output /content/train.zip
```

![1682804616455](2.猫狗图像识别.assets/1682804616455.png)

首先从kaggle下载Dogs vs. Cats数据集，下载下来是一个train.zip格式的文件。由于谷歌的Colab上传文件太慢，可以先上传到oneDrive平台，再通过curl从平台下载下来。

![1682804683726](2.猫狗图像识别.assets/1682804683726.png)

可以看到train.zip文件有500多M，说明下载成功。

## 步骤二（解压并提取数据）

```
!unzip -qq train.zip
```

![1682804797460](2.猫狗图像识别.assets/1682804797460.png)

解压之后多了一个train目录

```
import os, shutil, pathlib
original_dir = pathlib.Path("train")   
new_base_dir = pathlib.Path("cats_vs_dogs_small")   

def make_subset(subset_name, start_index, end_index):   
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg"
                  for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train", start_index=0, end_index=1000)   
make_subset("validation", start_index=1000, end_index=1500)   
make_subset("test", start_index=1500, end_index=2500) 
```

下载数据并解压后，我们将创建一个新数据集，其中包含 3 个子集：训练集，每个类别各 1000 个样本；验证集，每个类别各 500 个样本；测试集，每个类别各 1000 个样本。我们通过调用几次 shutil 来创建这个子数据集。

![1682804992069](2.猫狗图像识别.assets/1682804992069.png)

发现多了一个cats_vs_dogs_small目录

![1682805097608](2.猫狗图像识别.assets/1682805097608.png)

train是用每个类别的前 1000 张图像创建的训练子集，test是 用每个类别接下来的 500 张图像创建验证子集 ，validation是用每个类别接下来的 1000 张图像创建测试子集 。

现在我们有 2000 张训练图像、1000 张验证图像和 2000 张测试图像。在这 3 个集合中，两个类别的样本数相同，所以这是一个均衡的二分类问题，分类精度可作为衡量成功的指标。

## 步骤三（构建模型）

```
from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(180, 180, 3))  
x = layers.Rescaling(1./255)(inputs)   
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)
```

卷积神经网络由 Conv2D 层（使用 relu 激活函数）和 MaxPooling2D 层交替堆叠而成。但因为这里要处理更大的图像和更复杂的问题，所以需要相应地增大模型，增加两个 Conv2D+MaxPooling2D 的组合。这样做既可以增大模型容量，又可以进一步缩小特征图尺寸，使其在进入 Flatten 层时尺寸不会太大。本例初始输入的尺寸为 180 像素×180 像素（这是一个随意的选择），最后在 Flatten 层之前的特征图尺寸为 7×7。

因为这是一个二分类问题，所以模型的最后一层是使用 sigmoid 激活函数的单个单元（大小为 1 的 Dense 层）。这个单元表示的是模型认为样本属于某个类别的概率。

```
model.summary()
```

![1682805518195](2.猫狗图像识别.assets/1682805518195.png)

在模型中，特征图的深度逐渐增大（从 32 增大到 256），而特征图的尺寸则逐渐缩小（从 178×178 缩小到 7×7）。几乎所有卷积神经网络都是这种模式。

模型最开始是一个 Rescaling 层，它将图像输入（初始取值范围是 [0, 255] 区间）的取值范围缩放到 [0, 1] 区间。

## 步骤四（编译）

```
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])
```

模型编译将使用 rmsprop 优化器。模型最后一层是单一的 sigmoid 单元，所以我们将使用二元交叉熵作为损失函数

## 步骤五（数据预处理）

```
from tensorflow.keras.utils import image_dataset_from_directory
train_dataset = image_dataset_from_directory(
    new_base_dir / "train",
    image_size=(180, 180),
    batch_size=32)
validation_dataset = image_dataset_from_directory(
    new_base_dir / "validation",
    image_size=(180, 180),
    batch_size=32)
test_dataset = image_dataset_from_directory(
    new_base_dir / "test",
    image_size=(180, 180),
    batch_size=32)
```

将数据输入模型之前，应该将数据格式化为经过预处理的浮点数张量。当前数据以 JPEG 文件的形式存储在硬盘上，所以数据预处理步骤大致如下。

- 读取 JPEG 文件。

- 将 JPEG 文件解码为 RGB 像素网格。

- 将这些像素网格转换为浮点数张量。

- 将这些张量调节为相同大小（本例为 180×180）。

- 将数据打包成批量（一个批量包含 32 张图像）。

Keras 拥有自动完成这些步骤的工具。具体地说，Keras 包含实用函数 image_dataset_from_directory()，它可以快速建立数据管道，自动将磁盘上的图像文件转换为预处理好的张量批量。

调用 image_dataset_from_directory(directory)，首先会列出 directory 的子目录，并假定每个子目录都包含某一个类别的图像。然后，它会为每个子目录下的图像文件建立索引。最后，它会创建并返回一个 tf.data.Dataset 对象，用于读取这些文件、打乱其顺序、将其调节为相同大小并打包成批量。

## 步骤六（利用 Dataset 训练模型）

```
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=30,
    validation_data=validation_dataset,
    callbacks=callbacks)
```

![1682806387442](2.猫狗图像识别.assets/1682806387442.png)

我们将使用 fit() 方法的 validation_data 参数来监控模型在另一个 Dataset 对象上的验证指标。

请注意，我们还将使用 ModelCheckpoint 回调函数，在每轮过后保存模型。我们将指定文件的保存路径，并设置参数 save_best_only=True 和 monitor="val_loss"。这两个参数的作用是，只有当 val_loss 指标的当前值低于训练过程之前的所有值时，回调函数才会保存一个新文件（覆盖之前的文件）。这样做可以保证保存的文件始终包含最佳训练轮次的模型状态，即在验证数据上取得最佳性能的模型状态。因此，如果出现过拟合，我们不必用较少的轮数重新训练一个新模型，只需重新加载已保存的文件。

## 步骤七（绘制精度曲线和损失曲线）

```
import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

![1682806592667](2.猫狗图像识别.assets/1682806592667.png)

![1682806625953](2.猫狗图像识别.assets/1682806625953.png)

可以看出过拟合的特征。训练精度随时间线性增加，直到接近 100%，而验证精度的最大值只有 75%。验证损失在仅 10 轮之后就达到最小值，然后在一段时间内变化不大，而训练损失则随着训练的进行一直线性减小。

## 步骤八（在测试集上评估模型）

```
test_model = keras.models.load_model("convnet_from_scratch.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")
```

我们得到的测试精度为 70%。（由于神经网络初始化的随机性，你得到的结果可能会有不到 1% 的差距。）由于训练样本相对较少（2000 个），因此过拟合是我们最关心的问题。下面使用数据增强方法来降低过拟合。

## 步骤九（数据增强）

```
from keras import layers
data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)
```

数据增强是指从现有的训练样本中生成更多的训练数据，做法是利用一些能够生成可信图像的随机变换来增强（augment）样本。数据增强的目标是，模型在训练时不会两次查看完全相同的图片。这有助于模型观察到数据的更多内容，从而具有更强的泛化能力。

在 Keras 中，具体实现方法是一开始就为模型添加一些数据增强层。比如对图像进行随机变换，在模型中，我们将数据增强代码块放在 Rescaling 层之前。

这里只列出了几种可用的数据增强层：

- RandomFlip("horizontal")：将水平翻转应用于随机抽取的 50% 的图像。

- RandomRotation(0.1)：将输入图像在 [−10%, +10%] 的范围随机旋转（这个范围是相对于整个圆的比例，用角度表示的话，范围是 [−36°, +36° ]）。
- RandomZoom(0.2)：放大或缩小图像，缩放比例在 [−20%, +20%] 范围内随机取值。

```
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for images, _ in train_dataset.take(1):   
    for i in range(9):
        augmented_images = data_augmentation(images)   
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype("uint8"))   
        plt.axis("off")
```

![1683307158072](2.猫狗图像识别.assets/1683307158072.png)

上图随机显示了几张增强后的训练图像。 

如果使用这种数据增强技巧来训练新模型，那么模型将永远不会两次看到同样的输入。但模型看到的输入仍然是高度相关的，因为这些输入都来自于少量的原始图像。我们无法生成新信息，只能将现有信息重新组合。因此，这种方法可能不足以完全消除过拟合。为了进一步降低过拟合，我们还会在模型的密集连接分类器之前添加一个 Dropout 层。

关于随机图像增强层，你应该知道一点：就像 Dropout 层一样，它在推断过程中（调用 predict() 或 evaluate() 时）是不起作用的。在评估过程中，模型的表现与不采用数据增强和 dropout 时一样。

## 步骤十（重新定义模型）

```
inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])
```

使用数据增强和 dropout 重新定义模型。

## 步骤十一（训练模型）

```
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch_with_augmentation.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=100,
    validation_data=validation_dataset,
    callbacks=callbacks)

```

因为预计在训练过程中过拟合会较迟出现，所以我们将训练约 3 倍的轮数，即 100 轮。

![1683307502753](2.猫狗图像识别.assets/1683307502753.png)

## 步骤十一（绘制精度曲线和损失曲线）

```
import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

```

![1683307878485](2.猫狗图像识别.assets/1683307878485.png)



![1683307903065](2.猫狗图像识别.assets/1683307903065.png)

使用了数据增强和 dropout 之后，模型出现过拟合的时间要晚得多，大约在第 60～70 轮（与此相对，原始模型在第 10 轮就出现过拟合）。验证精度最终保持在 80%～85% 的范围内，与第一次尝试相比有了很大的改进。

```
test_model = keras.models.load_model(
    "convnet_from_scratch_with_augmentation.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")
```

![1683307993746](2.猫狗图像识别.assets/1683307993746.png)

测试精度为 83.1%。相比之前的70%有了很大的提升！通过进一步调节模型配置（比如每个卷积层的滤波器数量或者模型层数），我们可以得到更高的精度，可能达到 90%。但事实证明，仅通过从头开始训练自己的卷积神经网络，再想提高精度十分困难，因为可用的数据太少了。要想在这个问题上进一步提高精度，我们可以使用预训练模型。